{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "hidden_size   = 100  # hidden layer's size\n",
    "seq_length    = 25   # number of steps to unroll\n",
    "learning_rate = 1e-1\n",
    "vocab_size = 51\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vocab\n",
    "vocab_ = vocab.VocabBuilder('ptb.char.train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features,labels,mode,params,config):\n",
    "    #size of x - [time_step,batch_size,vocab_size]\n",
    "    #create a LSTMcell of size hidden_size\n",
    "    x = features['x']\n",
    "    print(x.shape)\n",
    "    #unstack in time steps (that is the 2nd dimension)\n",
    "    x = tf.unstack(x,seq_length,1)\n",
    "    rnn_cell = rnn.BasicLSTMCell(hidden_size)\n",
    "    outputs, states = rnn.static_rnn(cell=rnn_cell,inputs=x,dtype=tf.float64)\n",
    "    #create variables for softmax weight and bias\n",
    "    softmax_w = tf.get_variable(name='softmax_w', shape=[hidden_size,vocab_size],dtype=tf.float64,initializer=tf.initializers.truncated_normal())\n",
    "    softmax_b = tf.get_variable(name='softmax_b', shape=[1,vocab_size],dtype=tf.float64,initializer=tf.initializers.zeros())\n",
    "    \n",
    "    output_sequence_logits = []\n",
    "    for output in outputs:\n",
    "        output_sequence_logits.append(tf.matmul(output,softmax_w) + softmax_b)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_sequence_logits,labels=labels))\n",
    "    print(loss)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optmizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        specs = dict(mode=mode,loss=loss,train_op=optmizer.minimize(loss))\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(**specs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generator(filename,seq_len):\n",
    "    def generator():\n",
    "        with open(filename, 'r') as f:\n",
    "            char_list = f.read()\n",
    "            clist=[]\n",
    "            for i in range(0,len(char_list),2):\n",
    "                clist.append(char_list[i])\n",
    "            p=0\n",
    "            while p+seq_len+1<=len(clist):\n",
    "                input_ = clist[p:p+seq_len]\n",
    "                output_ = clist[p+1:p+1+seq_len]\n",
    "                p = p+seq_len\n",
    "                yield dict(x=vocab_.getOneHot(input_),y=vocab_.getOneHot(output_))\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "train_input_fn = generator_input_fn(x=input_generator('ptb.char.train.txt',seq_length),target_key='y',shuffle=False,batch_size=batch_size,queue_capacity = 10*batch_size,num_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x000001DBC4278EA0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn=model_fn,model_dir=\"./BasicLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train(input_fn=train_input_fn,steps=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

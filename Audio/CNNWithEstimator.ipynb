{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = '.\\\\' # unzipped train and test data\n",
    "OUTDIR = '.\\\\CNN' # just a random name\n",
    "# Data Loading\n",
    "import os\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train and 6798 val samples\n"
     ]
    }
   ],
   "source": [
    "#possible words for our training, all other words will go in unkown\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split() \n",
    "#converting name to id and otherwise. Will be used during printing test result and reading input\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\\\\\\\)?(\\w+)\\\\\\\\([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train\\\\audio\\\\*\\\\*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train\\\\validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    #A simple fix for windows machine\n",
    "    for i in range(len(validation_files)):\n",
    "        validation_files[i] = validation_files[i].replace('/','\\\\')\n",
    "    valset = set()\n",
    "    #add validation files' ids to a set and put them in valset. Other files will go in trainset. \n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label_id, uid, entry)\n",
    "            #print(uid)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    return train, val\n",
    "\n",
    "trainset, valset = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "#below is a generator, which takes one dataset in this format [(class_id, user_id, path), ...] and\n",
    "#build wave input from wav file. Which will be later fed into tensorflow signal processing layer for spectrogram.\n",
    "def data_generator(data, params, mode='train'):\n",
    "    def generator():\n",
    "        #shuffle during train\n",
    "        if mode == 'train':\n",
    "            np.random.shuffle(data)\n",
    "        # Feel free to add any augmentation\n",
    "        for (label_id, uid, fname) in data:\n",
    "            try:\n",
    "                #read file in wave format\n",
    "                _, wav = wavfile.read(fname)\n",
    "                #scale down for neural network input\n",
    "                wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "                \n",
    "                L = 16000  # be aware, some files are shorter than 1 sec!\n",
    "                if len(wav) < L:\n",
    "                    continue\n",
    "                # let's generate more silence!\n",
    "                samples_per_file = 1 if label_id != name2id['silence'] else 20\n",
    "                for _ in range(samples_per_file):\n",
    "                    if len(wav) > L:\n",
    "                        beg = np.random.randint(0, len(wav) - L)\n",
    "                    else:\n",
    "                        beg = 0\n",
    "                    #P.S. :- Yield will result a generator, which will later be easily used by the queue. \n",
    "                    yield dict(\n",
    "                        target=np.int32(label_id),\n",
    "                        wav=wav[beg: beg + L],\n",
    "                    )\n",
    "            except Exception as err:\n",
    "                print(err, label_id, uid, fname)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "#define a baseline model with 4 convolution layer and then 2 dense layer with softmax for the output layer.\n",
    "def baseline(x, params, is_training):\n",
    "    #apply batch normalization and learn gamma and beta during training. \n",
    "    x = layers.batch_norm(x, is_training=is_training)\n",
    "    #Add 4 layers of convolution using loop with 16*(2**i) number of filters in each subsequent layer. \n",
    "    #kernel size 3x3\n",
    "    #stride 1\n",
    "    #max pooling with a kernel of size 2x2 with stride 2.\n",
    "    #also applied batch normalization\n",
    "    for i in range(4):\n",
    "        x = layers.conv2d(\n",
    "            x, 16 * (2 ** i), 3, 1,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            normalizer_fn=layers.batch_norm if params.use_batch_norm else None,\n",
    "            normalizer_params={'is_training': is_training}\n",
    "        )\n",
    "        x = layers.max_pool2d(x, 2, 2)\n",
    "\n",
    "    # just take two kind of pooling and then mix them, why not :)\n",
    "    mpool = tf.reduce_max(x, axis=[1, 2], keep_dims=True)\n",
    "    apool = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n",
    "\n",
    "    x = 0.5 * (mpool + apool)\n",
    "    # we can use conv2d 1x1 instead of dense\n",
    "    x = layers.conv2d(x, 128, 1, 1, activation_fn=tf.nn.elu)\n",
    "    x = tf.nn.dropout(x, keep_prob=params.keep_prob if is_training else 1.0)\n",
    "    \n",
    "    # again conv2d 1x1 instead of dense layer\n",
    "    logits = layers.conv2d(x, params.num_classes, 1, 1, activation_fn=None)\n",
    "    return tf.squeeze(logits, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_handler(features, labels, mode, params, config):\n",
    "    # Im really like to use make_template instead of variable_scopes and re-usage\n",
    "    #make_template ???\n",
    "    extractor = tf.make_template(\n",
    "        'extractor', baseline,\n",
    "        create_scope_now_=True,\n",
    "    )\n",
    "    # wav is a waveform signal with shape (16000, )\n",
    "    wav = features['wav']\n",
    "    # we want to compute spectograms by means of short time fourier transform:\n",
    "    specgram = tf.contrib.signal.stft(\n",
    "        wav,\n",
    "        400,  # 16000 [samples per second] * 0.025 [s] -- default stft window frame\n",
    "        160,  # 16000 * 0.010 -- default stride\n",
    "    )\n",
    "    # specgram is a complex tensor, so split it into abs and phase parts:\n",
    "    #phase = tf.angle(specgram) / np.pi\n",
    "    phase = tf.atan2(tf.imag(specgram),tf.real(specgram)) / np.pi\n",
    "    # log(1 + abs) is a default transformation for energy units\n",
    "    amp = tf.log1p(tf.abs(specgram))\n",
    "    \n",
    "    x = tf.stack([amp, phase], axis=3) # shape is [bs, time, freq_bins, 2]\n",
    "    x = tf.to_float(x)  # we want to have float32, not float64\n",
    "\n",
    "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        # some lr tuner, you could use move interesting functions\n",
    "        def learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(\n",
    "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer=lambda lr: tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True),\n",
    "            learning_rate_decay_fn=learning_rate_decay_fn,\n",
    "            clip_gradients=params.clip_gradients,\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        prediction = tf.argmax(logits, axis=-1)\n",
    "        acc, acc_op = tf.metrics.mean_per_class_accuracy(\n",
    "            labels, prediction, params.num_classes)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=dict(\n",
    "                acc=(acc, acc_op),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'label': tf.argmax(logits, axis=-1),  # for probability just take tf.nn.softmax()\n",
    "            'sample': features['sample'], # it's a hack for simplicity\n",
    "        }\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    return tf.estimator.EstimatorSpec(**specs)\n",
    "\n",
    "\n",
    "def create_model(config=None, hparams=None):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_handler,\n",
    "        config=config,\n",
    "        params=hparams,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params=dict(\n",
    "    seed=2018,\n",
    "    batch_size=64,\n",
    "    keep_prob=0.5,\n",
    "    learning_rate=1e-3,\n",
    "    clip_gradients=15.0,\n",
    "    use_batch_norm=True,\n",
    "    num_classes=len(POSSIBLE_LABELS),\n",
    ")\n",
    "\n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "os.makedirs(os.path.join(OUTDIR, 'eval'), exist_ok=True)\n",
    "model_dir = OUTDIR\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001BC9ACDFDA0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '.\\\\CNN'}\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "WARNING:tensorflow:From C:\\Users\\sk111\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\generator_io.py:120: enqueue_data (from tensorflow.contrib.learn.python.learn.dataframe.queues.feeding_functions) is deprecated and will be removed after 2017-06-15.\n",
      "Instructions for updating:\n",
      "Moved to tf.contrib.training.enqueue_data.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from .\\CNN\\model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into .\\CNN\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.176213, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 5.58757\n",
      "INFO:tensorflow:loss = 0.255975, step = 10101 (17.898 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk111\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.59659\n",
      "INFO:tensorflow:loss = 0.192098, step = 10201 (17.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.57753\n",
      "INFO:tensorflow:loss = 0.472814, step = 10301 (17.929 sec)\n"
     ]
    }
   ],
   "source": [
    "# it's a magic function :)\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "            \n",
    "train_input_fn = generator_input_fn(\n",
    "    x=data_generator(trainset, hparams, 'train'),\n",
    "    target_key='target',  # you could leave target_key in features, so labels in model_handler will be empty\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "\n",
    "val_input_fn = generator_input_fn(\n",
    "    x=data_generator(valset, hparams, 'val'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "            \n",
    "\n",
    "def _create_my_experiment(run_config, hparams):\n",
    "    exp = tf.contrib.learn.Experiment(\n",
    "        estimator=create_model(config=run_config, hparams=hparams),\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=val_input_fn,\n",
    "        train_steps=10000, # just randomly selected params\n",
    "        eval_steps=200,  # read source code for steps-epochs ariphmetics\n",
    "        train_steps_per_iteration=1000,\n",
    "    )\n",
    "    return exp\n",
    "\n",
    "tf.contrib.learn.learn_runner.run(\n",
    "    experiment_fn=_create_my_experiment,\n",
    "    run_config=run_config,\n",
    "    schedule=\"continuous_train_and_eval\",\n",
    "    hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
